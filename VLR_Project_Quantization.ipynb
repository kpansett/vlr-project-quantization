{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VLR Project Quantization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kpansett/vlr-project-quantization/blob/main/VLR_Project_Quantization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42WURlKBFJj2"
      },
      "outputs": [],
      "source": [
        "# !pip install onnx\n",
        "# !pip install --upgrade onnxruntime==1.7.0\n",
        "# !pip install --upgrade onnxruntime-tools\n",
        "# !pip install --upgrade transformers\n",
        "# !pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall onnxruntime\n",
        "# !pip uninstall onnxruntime-gpu"
      ],
      "metadata": {
        "id": "0aazmuoMK5EQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "import time\n",
        "import torch\n",
        "\n",
        "import onnx\n",
        "import onnxruntime\n",
        "\n",
        "import transformers"
      ],
      "metadata": {
        "id": "KD_NQfP9tTlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "# model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "# text = \"Replace me by any text you'd like.\"\n",
        "\n",
        "# encoded_input = tokenizer(text, return_tensors='pt')\n",
        "# output = model(**encoded_input)"
      ],
      "metadata": {
        "id": "KwZYjed0tqBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoded_input[\"input_ids\"]\n",
        "# encoded_input[\"attention_mask\"]"
      ],
      "metadata": {
        "id": "Sm8JvGBNEW-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !gdown --id 1B3gzyzuDN1DU0lvt2kDz2nTTwSKWqzV5\n",
        "# !gdown --id 1VolF9P9cPSuD8CZMjwbKW20wUrAIaEFK\n",
        "# !gdown --id 1vhdtH3iFaoZuMqOGm-8YM-diPWVfRJzv\n",
        "# !gdown --id 1bv6_pZOsXW53EhlwU0ZgSk03uzFI61pN\n",
        "# !gdown --id 1XFz1Vtz7MCBLn4_1QEojhFJ5Iw3eH3X4"
      ],
      "metadata": {
        "id": "PQFJiKBj0ilK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "Nxu8Fk90rnF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/zengyan-97/X-VLM.git"
      ],
      "metadata": {
        "id": "kk7TaD_41Gjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import yaml\n",
        "sys.path.append(\"X-VLM/\")\n",
        "from models.xvlm import *\n",
        "from models.model_retrieval import *"
      ],
      "metadata": {
        "id": "m2oEQwjT2dEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cesmrVL834qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_path = \"/content/X-VLM/configs/Retrieval_coco.yaml\"\n",
        "\n",
        "with open(config_path, 'r') as stream:\n",
        "    config = yaml.safe_load(stream)"
      ],
      "metadata": {
        "id": "0Ajrz-4f4RGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cd X-VLM && mkdir data && cd data && rm -rf bert-base-uncased"
      ],
      "metadata": {
        "id": "FaxtWX4-L-OG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !sudo apt-get install git-lfs\n",
        "# !cd X-VLM && mkdir data\n",
        "# !cd X-VLM/data && git lfs install\n",
        "# !cd X-VLM/data && git clone https://huggingface.co/bert-base-uncased"
      ],
      "metadata": {
        "id": "zdw4bMclINs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LlmWkwvn69MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config[\"text_config\"] = os.path.join(\"X-VLM\", config[\"text_config\"])\n",
        "config[\"vision_config\"] = os.path.join(\"X-VLM\", config[\"vision_config\"])\n",
        "config[\"text_encoder\"] = os.path.join(\"X-VLM\", config[\"text_encoder\"])\n",
        "config[\"train_file\"][0] = os.path.join(\"X-VLM\", config[\"train_file\"][0])\n",
        "config[\"val_file\"] = os.path.join(\"X-VLM\", config[\"val_file\"])\n",
        "config[\"test_file\"] = os.path.join(\"X-VLM\", config[\"test_file\"])"
      ],
      "metadata": {
        "id": "xEiz8-3s6uyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# config"
      ],
      "metadata": {
        "id": "4d8zql1ODWsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = XVLM(config=config)\n",
        "\n",
        "# model = XVLMBase(config=config, load_vision_params=False, load_text_params=False,\n",
        "#                  use_contrastive_loss=True, use_matching_loss=True, use_mlm_loss=False, use_bbox_loss=True, \n",
        "#                  config_text=None)\n"
      ],
      "metadata": {
        "id": "gkfYKkeC27Yz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "487479c8-3a28-4c03-ede3-12a114a7e3eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !cd X-VLM/data && wget https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window7_224_22k.pth"
      ],
      "metadata": {
        "id": "Qcazc9gpBE-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ckpt_rpath = \"/content/4m_base_model_state_step_199999.th\"\n",
        "ckpt_rpath = \"/content/checkpoint_best.pth\"\n",
        "model.load_pretrained(ckpt_rpath, config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLdcBJ-l_qUX",
        "outputId": "f52a55b3-a04e-4907-d11a-ccabfe0f73f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Loading pretrained vision encoder\n",
            "### Loading pretrained text encoder\n",
            "load checkpoint from /content/checkpoint_best.pth\n",
            "missing_keys:  []\n",
            "unexpected_keys:  []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install ruamel.yaml\n",
        "# !pip install pycocoevalcap"
      ],
      "metadata": {
        "id": "PX4QcEmprL2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataset import *"
      ],
      "metadata": {
        "id": "-zQViCw1wTHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model"
      ],
      "metadata": {
        "id": "vFR9tecY4kAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# config"
      ],
      "metadata": {
        "id": "L49SxPtGwltF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# quantize model\n",
        "quantized_model = torch.quantization.quantize_dynamic(\n",
        "    model, {torch.nn.Linear}, dtype=torch.qint8\n",
        ")\n",
        "\n",
        "#print(quantized_model)\n",
        "\n",
        "def print_size_of_model(model):\n",
        "    torch.save(model.state_dict(), \"temp.p\")\n",
        "    print('Size (MB):', os.path.getsize(\"temp.p\")/(1024*1024))\n",
        "    os.remove('temp.p')\n",
        "\n",
        "print_size_of_model(model)\n",
        "print_size_of_model(quantized_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xrdieUK40UB",
        "outputId": "23c55c1b-6e39-4dcd-ba97-56890b0cf884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size (MB): 829.4066343307495\n",
            "Size (MB): 287.1118965148926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quantized_model"
      ],
      "metadata": {
        "id": "adStyeV8HobJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wlJQYLArrCda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import tempfile\n",
        "import torch\n",
        "import torch.distributed as dist\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.multiprocessing as mp\n",
        "\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "\n",
        "def setup(rank, world_size):\n",
        "    os.environ['MASTER_ADDR'] = 'localhost'\n",
        "    os.environ['MASTER_PORT'] = '12355'\n",
        "\n",
        "    # initialize the process group\n",
        "    dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n",
        "\n",
        "def cleanup():\n",
        "    dist.destroy_process_group()\n",
        "\n",
        "# dist.init_process_group(backend=\"gloo\", rank=1, world_size=1)\n",
        "setup(rank=0, world_size=1)"
      ],
      "metadata": {
        "id": "f6JFfvSHFcmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "id": "swVrpbC-A3Vg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a797284-fb1b-40a2-ce56-486ec5c2588b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XVLM(\n",
              "  (vision_encoder): SwinTransformer(\n",
              "    (patch_embed): PatchEmbed(\n",
              "      (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
              "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "    (layers): ModuleList(\n",
              "      (0): BasicLayer(\n",
              "        dim=128, input_resolution=(96, 96), depth=2\n",
              "        (blocks): ModuleList(\n",
              "          (0): SwinTransformerBlock(\n",
              "            dim=128, input_resolution=(96, 96), num_heads=4, window_size=12, shift_size=0, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=128, window_size=(12, 12), num_heads=4\n",
              "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): Identity()\n",
              "            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): SwinTransformerBlock(\n",
              "            dim=128, input_resolution=(96, 96), num_heads=4, window_size=12, shift_size=6, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=128, window_size=(12, 12), num_heads=4\n",
              "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (downsample): PatchMerging(\n",
              "          input_resolution=(96, 96), dim=128\n",
              "          (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicLayer(\n",
              "        dim=256, input_resolution=(48, 48), depth=2\n",
              "        (blocks): ModuleList(\n",
              "          (0): SwinTransformerBlock(\n",
              "            dim=256, input_resolution=(48, 48), num_heads=8, window_size=12, shift_size=0, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=256, window_size=(12, 12), num_heads=8\n",
              "              (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): SwinTransformerBlock(\n",
              "            dim=256, input_resolution=(48, 48), num_heads=8, window_size=12, shift_size=6, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=256, window_size=(12, 12), num_heads=8\n",
              "              (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (downsample): PatchMerging(\n",
              "          input_resolution=(48, 48), dim=256\n",
              "          (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
              "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (2): BasicLayer(\n",
              "        dim=512, input_resolution=(24, 24), depth=18\n",
              "        (blocks): ModuleList(\n",
              "          (0): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=0, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=6, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=0, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=6, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=0, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=6, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=0, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=6, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=0, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=6, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=0, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=6, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (12): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=0, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (13): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=6, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (14): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=0, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (15): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=6, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (16): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=0, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (17): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=6, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (downsample): PatchMerging(\n",
              "          input_resolution=(24, 24), dim=512\n",
              "          (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
              "          (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (3): BasicLayer(\n",
              "        dim=1024, input_resolution=(12, 12), depth=2\n",
              "        (blocks): ModuleList(\n",
              "          (0): SwinTransformerBlock(\n",
              "            dim=1024, input_resolution=(12, 12), num_heads=32, window_size=12, shift_size=0, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=1024, window_size=(12, 12), num_heads=32\n",
              "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): SwinTransformerBlock(\n",
              "            dim=1024, input_resolution=(12, 12), num_heads=32, window_size=12, shift_size=0, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=1024, window_size=(12, 12), num_heads=32\n",
              "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
              "  )\n",
              "  (text_encoder): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (vision_proj): Linear(in_features=1024, out_features=256, bias=True)\n",
              "  (text_proj): Linear(in_features=768, out_features=256, bias=True)\n",
              "  (itm_head): Sequential(\n",
              "    (0): Linear(in_features=768, out_features=1536, bias=True)\n",
              "    (1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "    (2): GELU()\n",
              "    (3): Linear(in_features=1536, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from models.tokenization_bert import BertTokenizer\n",
        "from models.tokenization_roberta import RobertaTokenizer"
      ],
      "metadata": {
        "id": "y-q9J8dgr5p9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !tar -xvf finetune.tar -C X-VLM/data/"
      ],
      "metadata": {
        "id": "y_aYCwFUsCaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config[\"prompt\"] = \"\""
      ],
      "metadata": {
        "id": "odEuyB1B4QXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget http://images.cocodataset.org/zips/val2014.zip\n",
        "# !wget http://images.cocodataset.org/zips/train2014.zip"
      ],
      "metadata": {
        "id": "UpsLYnN86D40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir images\n",
        "# !cd images && mkdir coco\n",
        "# !unzip val2014.zip -d images/coco/\n",
        "# !unzip train2014.zip -d images/coco/"
      ],
      "metadata": {
        "id": "QrFhX_1o6Dyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wxozvOat_V4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_dataset, val_dataset, test_dataset = create_dataset('caption_coco', config)\n",
        "train_dataset, val_dataset, test_dataset = create_dataset('re', config)"
      ],
      "metadata": {
        "id": "ruFzCxQ-40XX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d6fb1ad-e04c-4f71-f404-459584bfa797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:853: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_dataset[0]"
      ],
      "metadata": {
        "id": "CPiyOm1J-zA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samplers = [None, None, None]\n",
        "train_loader, val_loader, test_loader = create_loader([train_dataset, val_dataset, test_dataset], samplers,\n",
        "                                                      batch_size=[4,4,4],\n",
        "                                                      num_workers=[4, 4, 4],\n",
        "                                                      is_trains=[True, False, False],\n",
        "                                                      collate_fns=[None, None, None])"
      ],
      "metadata": {
        "id": "LcJfmCqWy6GP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "print(\"### Total Params: \", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "\n",
        "if config['use_roberta']:\n",
        "    tokenizer = RobertaTokenizer.from_pretrained(config['text_encoder'])\n",
        "else:\n",
        "    tokenizer = BertTokenizer.from_pretrained(config['text_encoder'])\n"
      ],
      "metadata": {
        "id": "i8sxgugk1mji",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fb3b950-0872-4d83-c142-2ea973e3264f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Total Params:  213959547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# texts = val_loader.dataset.text\n",
        "# num_text = len(texts)\n",
        "# text_bs = 2  # 256\n",
        "# text_feats = []\n",
        "# text_embeds = []  \n",
        "# text_atts = []\n",
        "# for i in range(0, num_text, text_bs):\n",
        "#     text = texts[i: min(num_text, i + text_bs)]\n",
        "#     text_input = tokenizer(text, padding='max_length', truncation=True, max_length=config['max_tokens'],\n",
        "#                             return_tensors=\"pt\").to(device)\n",
        "#     text_output = model.text_encoder(text_input.input_ids, attention_mask=text_input.attention_mask, mode='text')\n",
        "#     text_feat = text_output.last_hidden_state\n",
        "#     text_embed = F.normalize(model.text_proj(text_feat[:, 0, :]))\n",
        "#     text_embeds.append(text_embed)\n",
        "#     text_feats.append(text_feat)\n",
        "#     text_atts.append(text_input.attention_mask)\n",
        "#     break\n",
        "\n",
        "# text_embeds = torch.cat(text_embeds, dim=0)\n",
        "# text_feats = torch.cat(text_feats, dim=0)\n",
        "# text_atts = torch.cat(text_atts, dim=0)"
      ],
      "metadata": {
        "id": "z-_eOTTFKFKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text_atts.reshape(1, 2, 40)"
      ],
      "metadata": {
        "id": "SRS91oyLCCW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoded_input[\"input_ids\"]\n",
        "# encoded_input[\"attention_mask\"]\n",
        "\n",
        "# inputs = {'image': torch.rand(1,3, 384, 384, dtype=torch.float).cuda(),\n",
        "#                     'text_ids': torch.ones(1, 2, 40, dtype=torch.int64).cuda(),\n",
        "#                     'text_atts': text_atts.reshape(1, 2, 40)}"
      ],
      "metadata": {
        "id": "55d9Lo4fEruq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model(inputs['image'], encoded_input[\"input_ids\"], encoded_input[\"attention_mask\"])"
      ],
      "metadata": {
        "id": "ReBu2lXlFwI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for data in train_loader:\n",
        "#     print(len(data))\n",
        "#     break\n",
        "\n",
        "# for data in val_loader:\n",
        "#     print(data)\n",
        "#     break"
      ],
      "metadata": {
        "id": "P0dQtb910MWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = np.load(\"train_loader.npz\")\n",
        "# train_data[\"images\"], train_data[\"text_ids\"], train_data[\"text_attn\"]"
      ],
      "metadata": {
        "id": "qvbUPHJ5bTzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wFEx9txSca3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.cuda()\n",
        "start = time.time()\n",
        "bs = 4\n",
        "for idx in range(0, 500, bs):\n",
        "    if idx >= 4:\n",
        "      break\n",
        "    inputs = {'image': torch.Tensor(train_data[\"images\"][idx:idx+bs]),\n",
        "          'text_ids': torch.LongTensor(train_data[\"text_ids\"][idx:idx+bs]), \n",
        "          'text_atts': torch.Tensor(train_data[\"text_attn\"][idx:idx+bs])}\n",
        "\n",
        "    outputs = model(inputs[\"image\"].cuda(), inputs[\"text_ids\"].cuda(), inputs[\"text_atts\"].cuda())\n",
        "\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "metadata": {
        "id": "_L8E2kqo25Tc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15445839-d74c-45df-ac68-973728f8034f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.6367626190185547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TcvRjMcbbU81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bVPO8U2ybU5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from models.tokenization_bert import BertTokenizer\n",
        "\n",
        "for i, (image, text, id) in enumerate(train_loader):\n",
        "    image = image.to(device, non_blocking=True)\n",
        "    # print(text)\n",
        "    # text = [\"abc def\"]*image.shape[0]\n",
        "    # print(text)\n",
        "    text_input = tokenizer(text, padding='longest', max_length=config['max_tokens'], return_tensors=\"pt\").to(device)\n",
        "\n",
        "    loss_itc, loss_itm = model(image, text_input.input_ids, text_input.attention_mask)\n",
        "    break"
      ],
      "metadata": {
        "id": "95O69yWLy_Th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {'image': image.cuda(),\n",
        "          'text_ids': text_input.input_ids, \n",
        "          'text_atts': text_input.attention_mask}"
      ],
      "metadata": {
        "id": "OPC-sSOPEBjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5YZ1rOcfPVn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def export_onnx_model(model, onnx_model_path):\n",
        "    with torch.no_grad():\n",
        "        # inputs = {'image': torch.rand(1,3, 384, 384, dtype=torch.float).cuda(),\n",
        "        #             'text_ids': encoded_input[\"input_ids\"].cuda(),\n",
        "        #             'text_atts': encoded_input[\"attention_mask\"].cuda()\n",
        "        #           }\n",
        "        outputs = model(**inputs)\n",
        "        # outputs = model(inputs['text_ids'], inputs['text_atts'])                         # model input (or a tuple for multiple inputs)\n",
        "\n",
        "        symbolic_names = {0: 'batch_size'}\n",
        "        symbolic_names1 = {0: 'batch_size', 1: 'seq_len'}\n",
        "\n",
        "        torch.onnx.export(model,                                            # model being run\n",
        "                    (\n",
        "                        inputs['image'],                             # model input (or a tuple for multiple inputs)\n",
        "                    inputs['text_ids'],\n",
        "                     inputs['text_atts']\n",
        "                     ),                                         # model input (or a tuple for multiple inputs)\n",
        "                    onnx_model_path,                                # where to save the model (can be a file or file-like object)\n",
        "                    opset_version=13,                                 # the ONNX version to export the model to\n",
        "                    do_constant_folding=True,                         # whether to execute constant folding for optimization\n",
        "                    input_names=[\n",
        "                                 'image',                         # the model's input names\n",
        "                                'text_ids', \n",
        "                                'text_atts'\n",
        "                                ],\n",
        "                    output_names=['output'],                    # the model's output names\n",
        "                    dynamic_axes={\n",
        "                        'image': symbolic_names,        # variable length axes\n",
        "                                'text_ids' : symbolic_names1,\n",
        "                                'text_atts' : symbolic_names1,\n",
        "                                'output' : symbolic_names\n",
        "                                },\n",
        "                          # operator_export_type=torch.onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK\n",
        "                          )\n",
        "        # logger.info(\"ONNX Model exported to {0}\".format(onnx_model_path))\n",
        "\n",
        "# export_onnx_model(model, \"xvlm2.onnx\")"
      ],
      "metadata": {
        "id": "m4a_9_Fxv0WQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def quantize_onnx_model(onnx_model_path, quantized_model_path):\n",
        "    from onnxruntime.quantization import quantize_dynamic, QuantType\n",
        "    import onnx\n",
        "    onnx_opt_model = onnx.load(onnx_model_path)\n",
        "    quantize_dynamic(onnx_model_path,\n",
        "                     quantized_model_path,\n",
        "                     weight_type=QuantType.QUInt8)\n",
        "\n",
        "    # logger.info(f\"quantized model saved to:{quantized_model_path}\")\n",
        "\n",
        "# quantize_onnx_model('xvlm2.onnx', 'xvlm2.opt.quant.onnx')\n",
        "\n",
        "print('ONNX full precision model size (MB):', os.path.getsize(\"xvlm2.onnx\")/(1024*1024))\n",
        "print('ONNX quantized model size (MB):', os.path.getsize(\"xvlm2.opt.quant.onnx\")/(1024*1024))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLpyvtYdP002",
        "outputId": "56590c9f-87de-43dc-bb10-3518fef30b9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ONNX full precision model size (MB): 1079.7703914642334\n",
            "ONNX quantized model size (MB): 300.550124168396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall onnxruntime-gpu\n",
        "# !pip uninstall onnxruntime\n",
        "# !pip install onnxruntime==1.7.0\n",
        "# !pip install onnxruntime-gpu==1.7.0"
      ],
      "metadata": {
        "id": "9uq1Fn8qEV2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from onnxruntime_tools import optimizer\n",
        "# from onnxruntime_tools.transformers.onnx_model_bert import BertOptimizationOptions\n",
        "\n",
        "# # disable embedding layer norm optimization for better model size reduction\n",
        "# opt_options = BertOptimizationOptions('bert')\n",
        "# opt_options.enable_embed_layer_norm = False\n",
        "\n",
        "# opt_model = optimizer.optimize_model(\n",
        "#     'bert.onnx',\n",
        "#     'bert', \n",
        "#     num_heads=12,\n",
        "#     hidden_size=768,\n",
        "#     optimization_options=opt_options)\n",
        "# opt_model.save_model_to_file('bert.opt.onnx')"
      ],
      "metadata": {
        "id": "dCTpiwUPwx-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VvlDSGBTxizP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sess_options = onnxruntime.SessionOptions()\n",
        "# sess_options.add_session_config_entry('session.load_model_format', 'ONNX')\n",
        "sess_options.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
        "session = onnxruntime.InferenceSession('xvlm2.opt.quant.onnx', sess_options, providers=['CUDAExecutionProvider'])"
      ],
      "metadata": {
        "id": "nzKTiRc1xitc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {'image': image.cpu().numpy(),\n",
        "          'text_ids': text_input.input_ids.cpu().numpy(), \n",
        "          'text_atts': text_input.attention_mask.cpu().numpy()}"
      ],
      "metadata": {
        "id": "IxrPBfwK4Vqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image.cpu().numpy()"
      ],
      "metadata": {
        "id": "B4pTA3ei4b_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "rucGgRqX_Qdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# images_all = []\n",
        "# text_ids_all = []\n",
        "# text_attn_all = []\n",
        "\n",
        "# batch_count = 0\n",
        "# for (image, text, id) in train_loader:\n",
        "#     if batch_count >= 125:\n",
        "#         break\n",
        "#     images_all.append(image.numpy())\n",
        "#     text_ids_all.append(text_input.input_ids.cpu().numpy())\n",
        "#     text_attn_all.append(text_input.attention_mask.cpu().numpy())\n",
        "#     batch_count += 1\n",
        "\n",
        "# images_all = np.vstack(images_all)\n",
        "# text_ids_all = np.vstack(text_ids_all)\n",
        "# text_attn_all = np.vstack(text_attn_all)"
      ],
      "metadata": {
        "id": "SNRAVzgjQw-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# np.savez(\"/content/drive/MyDrive/train_loader.npz\", images=images_all, text_ids=text_ids_all, text_attn=text_attn_all)"
      ],
      "metadata": {
        "id": "l-5h4szyRxOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = np.load(\"train_loader.npz\")\n",
        "# train_data[\"images\"], train_data[\"text_ids\"], train_data[\"text_attn\"]"
      ],
      "metadata": {
        "id": "7rot7jbbSu8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text_attn_all.shape"
      ],
      "metadata": {
        "id": "r9N0BlaDRcaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (image, text, id) in train_loader:\n",
        "    inputs = {'image': image.numpy(),\n",
        "          'text_ids': text_input.input_ids.cpu().numpy(), \n",
        "          'text_atts': text_input.attention_mask.cpu().numpy()}\n",
        "    \n",
        "    im = image.cuda()\n",
        "    tid = text_input.input_ids\n",
        "    ta = text_input.attention_mask\n",
        "    \n",
        "    break"
      ],
      "metadata": {
        "id": "0rwQ0hOQA2wB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "bs = 4\n",
        "for idx in range(0, 500, bs):\n",
        "    if idx >=40:\n",
        "      break\n",
        "    inputs = {'image': train_data[\"images\"][idx:idx+bs],\n",
        "          'text_ids': train_data[\"text_ids\"][idx:idx+bs], \n",
        "          'text_atts': train_data[\"text_attn\"][idx:idx+bs]}\n",
        "\n",
        "    # print(text_input.input_ids.shape)\n",
        "    outputs = session.run(None, inputs)\n",
        "    # break\n",
        "\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69n-nesIU8G1",
        "outputId": "27b80398-672f-4d05-a4f8-8e3ac764d5f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55.480478286743164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(onnxruntime.get_device())"
      ],
      "metadata": {
        "id": "yDtlLnuFiPK-",
        "outputId": "d74e3c63-347d-44ad-96ee-e6fa6c434f59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.cuda()\n",
        "start = time.time()\n",
        "bs = 10\n",
        "for idx in range(0, 500, bs):\n",
        "    inputs = {'image': torch.Tensor(train_data[\"images\"][idx:idx+bs]),\n",
        "          'text_ids': torch.LongTensor(train_data[\"text_ids\"][idx:idx+bs]), \n",
        "          'text_atts': torch.Tensor(train_data[\"text_attn\"][idx:idx+bs])}\n",
        "\n",
        "    # print(text_input.input_ids.shape)\n",
        "    outputs = model(inputs[\"image\"].cuda(), inputs[\"text_ids\"].cuda(), inputs[\"text_atts\"].cuda())\n",
        "    break\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "Ya6X7kp7Zt-r",
        "outputId": "df519120-b2ce-414d-93f1-4b542b2cac56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-e6635ddb82f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# print(text_input.input_ids.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text_atts\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/X-VLM/models/model_retrieval.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, image, text_ids, text_atts, idx)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_atts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mimage_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_atts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vision_embeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mtext_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text_embeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_atts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/X-VLM/models/xvlm.py\u001b[0m in \u001b[0;36mget_vision_embeds\u001b[0;34m(self, image, image_atts, idx_to_group_img)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \"\"\"\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx_to_group_img\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m             \u001b[0mimage_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvision_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m             \u001b[0mimage_atts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimage_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_atts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/X-VLM/models/swin_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, idx_to_group_img, image_atts, **kwargs)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# B L C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/X-VLM/models/swin_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/X-VLM/models/swin_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;31m# FFN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshortcut\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/X-VLM/models/swin_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 46.00 MiB (GPU 0; 15.90 GiB total capacity; 13.64 GiB already allocated; 37.75 MiB free; 14.73 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "for (image, text, id) in train_loader:\n",
        "    inputs = {'image': image.cpu().numpy(),\n",
        "          'text_ids': text_input.input_ids.cpu().numpy(), \n",
        "          'text_atts': text_input.attention_mask.cpu().numpy()}\n",
        "\n",
        "    # print(text_input.input_ids.shape)\n",
        "    outputs = session.run(None, inputs)\n",
        "    break\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azLZhGZi3ZYF",
        "outputId": "a07fbcc3-e8bd-4466-cca8-c3c25028f79b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.425128221511841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "count = 0\n",
        "for (image, text, id) in train_loader:\n",
        "    if count >= 125:\n",
        "        break\n",
        "    text_input = tokenizer(text, padding='longest', max_length=config['max_tokens'], return_tensors=\"pt\").to(device)\n",
        "    outputs = model(image.cuda(), text_input.input_ids, text_input.attention_mask)\n",
        "    count += 1\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdSfHQrA_lWK",
        "outputId": "a0bac9b5-89ce-4ac2-f073-154d30d10d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20.372811555862427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YvpPyP03ZOa",
        "outputId": "e9116e7d-0a4e-4ba3-aebd-bb6254330f2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(9.4024, device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor(5.4466, device='cuda:0', grad_fn=<NllLossBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "GzzDlB0n3ZK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "id": "UswawlvOPyko",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7a2f6cd2-dbe9-4988-8bce-9bc740f360e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.10.0+cu111'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Quantization\n",
        "* Data Loader \n",
        "    - Data: Flikr30k, Flikr8k\n",
        "* Evaluation\n",
        "* Presentation"
      ],
      "metadata": {
        "id": "Z8B3gDsG1TZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install libcudart==11.0.221\n",
        "# !pip install libcufft==10.2.1.245\n",
        "# !pip install libcurand==10.2.1.245\n",
        "# !pip install libcublasLt==11.2.0.252\n",
        "# !pip install libcublas==11.2.0.252\n",
        "# !pip install libcudnn==8.0.4"
      ],
      "metadata": {
        "id": "vdUNw6MtsmhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Retrieval import *"
      ],
      "metadata": {
        "id": "Vtib7zMpsgDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_without_ddp = quantized_model\n",
        "model_without_ddp = model"
      ],
      "metadata": {
        "id": "u3ZeMGHEHoJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "MSzRMUTyILvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_without_ddp.to(device)"
      ],
      "metadata": {
        "id": "QPOmeeAWIf7r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbac38b0-c1cc-48d0-a925-7604ebe17d46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XVLM(\n",
              "  (vision_encoder): SwinTransformer(\n",
              "    (patch_embed): PatchEmbed(\n",
              "      (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
              "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "    (layers): ModuleList(\n",
              "      (0): BasicLayer(\n",
              "        dim=128, input_resolution=(96, 96), depth=2\n",
              "        (blocks): ModuleList(\n",
              "          (0): SwinTransformerBlock(\n",
              "            dim=128, input_resolution=(96, 96), num_heads=4, window_size=12, shift_size=0, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=128, window_size=(12, 12), num_heads=4\n",
              "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): Identity()\n",
              "            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): SwinTransformerBlock(\n",
              "            dim=128, input_resolution=(96, 96), num_heads=4, window_size=12, shift_size=6, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=128, window_size=(12, 12), num_heads=4\n",
              "              (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (downsample): PatchMerging(\n",
              "          input_resolution=(96, 96), dim=128\n",
              "          (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
              "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicLayer(\n",
              "        dim=256, input_resolution=(48, 48), depth=2\n",
              "        (blocks): ModuleList(\n",
              "          (0): SwinTransformerBlock(\n",
              "            dim=256, input_resolution=(48, 48), num_heads=8, window_size=12, shift_size=0, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=256, window_size=(12, 12), num_heads=8\n",
              "              (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): SwinTransformerBlock(\n",
              "            dim=256, input_resolution=(48, 48), num_heads=8, window_size=12, shift_size=6, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=256, window_size=(12, 12), num_heads=8\n",
              "              (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (downsample): PatchMerging(\n",
              "          input_resolution=(48, 48), dim=256\n",
              "          (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
              "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (2): BasicLayer(\n",
              "        dim=512, input_resolution=(24, 24), depth=18\n",
              "        (blocks): ModuleList(\n",
              "          (0): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=0, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=6, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=0, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=6, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=0, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=6, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=0, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=6, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=0, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=6, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=0, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=6, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (12): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=0, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (13): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=6, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (14): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=0, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (15): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=6, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (16): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=0, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (17): SwinTransformerBlock(\n",
              "            dim=512, input_resolution=(24, 24), num_heads=16, window_size=12, shift_size=6, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=512, window_size=(12, 12), num_heads=16\n",
              "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (downsample): PatchMerging(\n",
              "          input_resolution=(24, 24), dim=512\n",
              "          (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
              "          (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (3): BasicLayer(\n",
              "        dim=1024, input_resolution=(12, 12), depth=2\n",
              "        (blocks): ModuleList(\n",
              "          (0): SwinTransformerBlock(\n",
              "            dim=1024, input_resolution=(12, 12), num_heads=32, window_size=12, shift_size=0, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=1024, window_size=(12, 12), num_heads=32\n",
              "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): SwinTransformerBlock(\n",
              "            dim=1024, input_resolution=(12, 12), num_heads=32, window_size=12, shift_size=0, mlp_ratio=4.0\n",
              "            (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn): WindowAttention(\n",
              "              dim=1024, window_size=(12, 12), num_heads=32\n",
              "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "              (softmax): Softmax(dim=-1)\n",
              "            )\n",
              "            (drop_path): DropPath()\n",
              "            (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): Mlp(\n",
              "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "              (act): GELU()\n",
              "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (drop): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
              "  )\n",
              "  (text_encoder): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (crossattention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (vision_proj): Linear(in_features=1024, out_features=256, bias=True)\n",
              "  (text_proj): Linear(in_features=768, out_features=256, bias=True)\n",
              "  (itm_head): Sequential(\n",
              "    (0): Linear(in_features=768, out_features=1536, bias=True)\n",
              "    (1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "    (2): GELU()\n",
              "    (3): Linear(in_features=1536, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# val_loader.dataset.text"
      ],
      "metadata": {
        "id": "DP1RRt31UbEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "print(\"Start evaluating\", flush=True)\n",
        "\n",
        "score_val_i2t, score_val_t2i, = evaluation(model_without_ddp, val_loader, tokenizer, device, config)\n",
        "# score_test_i2t, score_test_t2i = evaluation(model_without_ddp, test_loader, tokenizer, device, config)\n",
        "\n",
        "val_result = itm_eval(score_val_i2t, score_val_t2i, val_loader.dataset.txt2img, val_loader.dataset.img2txt)\n",
        "print(val_result)\n",
        "# test_result = itm_eval(score_test_i2t, score_test_t2i, test_loader.dataset.txt2img, test_loader.dataset.img2txt)\n",
        "# print(test_result)\n",
        "\n",
        "log_stats = {**{f'val_{k}': v for k, v in val_result.items()}}\n",
        "\n",
        "print(log_stats)"
      ],
      "metadata": {
        "id": "GKquj39MsTKT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d448ea4-8693-4a69-d1eb-a6d101120969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start evaluating\n",
            "Computing features for evaluation...\n",
            "Evaluation: [  0/501]  eta: 0:00:07    time: 0.0159  data: 0.0006  max mem: 6067\n",
            "Evaluation: [ 50/501]  eta: 0:02:11    time: 0.2963  data: 0.0000  max mem: 6097\n",
            "Evaluation: [100/501]  eta: 0:01:57    time: 0.2963  data: 0.0000  max mem: 6097\n",
            "Evaluation: [150/501]  eta: 0:01:43    time: 0.2964  data: 0.0000  max mem: 6097\n",
            "Evaluation: [200/501]  eta: 0:01:28    time: 0.2963  data: 0.0000  max mem: 6097\n",
            "Evaluation: [250/501]  eta: 0:01:14    time: 0.2964  data: 0.0000  max mem: 6100\n",
            "Evaluation: [300/501]  eta: 0:00:59    time: 0.2964  data: 0.0000  max mem: 6100\n",
            "Evaluation: [350/501]  eta: 0:00:44    time: 0.2969  data: 0.0000  max mem: 6220\n",
            "Evaluation: [400/501]  eta: 0:00:29    time: 0.2962  data: 0.0000  max mem: 6220\n",
            "Evaluation: [450/501]  eta: 0:00:15    time: 0.2962  data: 0.0000  max mem: 6220\n",
            "Evaluation: [500/501]  eta: 0:00:00    time: 0.2961  data: 0.0000  max mem: 6220\n",
            "Evaluation: Total time: 0:02:28 (0.2958 s / it)\n",
            "Evaluation: [   0/2507]  eta: 0:00:36    time: 0.0145  data: 0.0016  max mem: 6220\n",
            "Evaluation: [  50/2507]  eta: 0:11:54    time: 0.2962  data: 0.0000  max mem: 6220\n",
            "Evaluation: [ 100/2507]  eta: 0:11:46    time: 0.2962  data: 0.0000  max mem: 6220\n",
            "Evaluation: [ 150/2507]  eta: 0:11:33    time: 0.2960  data: 0.0000  max mem: 6220\n",
            "Evaluation: [ 200/2507]  eta: 0:11:20    time: 0.2962  data: 0.0000  max mem: 6220\n",
            "Evaluation: [ 250/2507]  eta: 0:11:06    time: 0.2962  data: 0.0000  max mem: 6220\n",
            "Evaluation: [ 300/2507]  eta: 0:10:51    time: 0.2963  data: 0.0000  max mem: 6220\n",
            "Evaluation: [ 350/2507]  eta: 0:10:37    time: 0.2963  data: 0.0000  max mem: 6220\n",
            "Evaluation: [ 400/2507]  eta: 0:10:22    time: 0.2964  data: 0.0000  max mem: 6220\n",
            "Evaluation: [ 450/2507]  eta: 0:10:08    time: 0.2962  data: 0.0000  max mem: 6220\n",
            "Evaluation: [ 500/2507]  eta: 0:09:53    time: 0.2963  data: 0.0000  max mem: 6220\n",
            "Evaluation: [ 550/2507]  eta: 0:09:38    time: 0.2961  data: 0.0000  max mem: 6220\n",
            "Evaluation: [ 600/2507]  eta: 0:09:24    time: 0.2961  data: 0.0000  max mem: 6220\n",
            "Evaluation: [ 650/2507]  eta: 0:09:09    time: 0.2961  data: 0.0000  max mem: 6220\n",
            "Evaluation: [ 700/2507]  eta: 0:08:54    time: 0.2963  data: 0.0000  max mem: 6263\n",
            "Evaluation: [ 750/2507]  eta: 0:08:39    time: 0.2962  data: 0.0000  max mem: 6263\n",
            "Evaluation: [ 800/2507]  eta: 0:08:25    time: 0.2960  data: 0.0000  max mem: 6263\n",
            "Evaluation: [ 850/2507]  eta: 0:08:10    time: 0.2962  data: 0.0000  max mem: 6263\n",
            "Evaluation: [ 900/2507]  eta: 0:07:55    time: 0.2964  data: 0.0000  max mem: 6263\n",
            "Evaluation: [ 950/2507]  eta: 0:07:40    time: 0.2964  data: 0.0000  max mem: 6263\n",
            "Evaluation: [1000/2507]  eta: 0:07:26    time: 0.2962  data: 0.0000  max mem: 6263\n",
            "Evaluation: [1050/2507]  eta: 0:07:11    time: 0.2962  data: 0.0000  max mem: 6263\n",
            "Evaluation: [1100/2507]  eta: 0:06:56    time: 0.2963  data: 0.0000  max mem: 6263\n",
            "Evaluation: [1150/2507]  eta: 0:06:41    time: 0.2963  data: 0.0000  max mem: 6263\n",
            "Evaluation: [1200/2507]  eta: 0:06:26    time: 0.2962  data: 0.0000  max mem: 6263\n",
            "Evaluation: [1250/2507]  eta: 0:06:12    time: 0.2962  data: 0.0000  max mem: 6263\n",
            "Evaluation: [1300/2507]  eta: 0:05:57    time: 0.2963  data: 0.0000  max mem: 6263\n",
            "Evaluation: [1350/2507]  eta: 0:05:42    time: 0.2961  data: 0.0000  max mem: 6263\n",
            "Evaluation: [1400/2507]  eta: 0:05:27    time: 0.2964  data: 0.0000  max mem: 6263\n",
            "Evaluation: [1450/2507]  eta: 0:05:12    time: 0.2961  data: 0.0000  max mem: 6263\n",
            "Evaluation: [1500/2507]  eta: 0:04:58    time: 0.2962  data: 0.0000  max mem: 6263\n",
            "Evaluation: [1550/2507]  eta: 0:04:43    time: 0.2963  data: 0.0000  max mem: 6263\n",
            "Evaluation: [1600/2507]  eta: 0:04:28    time: 0.2962  data: 0.0000  max mem: 6263\n",
            "Evaluation: [1650/2507]  eta: 0:04:13    time: 0.2963  data: 0.0000  max mem: 6263\n",
            "Evaluation: [1700/2507]  eta: 0:03:58    time: 0.2963  data: 0.0000  max mem: 6263\n",
            "Evaluation: [1750/2507]  eta: 0:03:44    time: 0.2962  data: 0.0000  max mem: 6263\n",
            "Evaluation: [1800/2507]  eta: 0:03:29    time: 0.2962  data: 0.0000  max mem: 6263\n",
            "Evaluation: [1850/2507]  eta: 0:03:14    time: 0.2961  data: 0.0000  max mem: 6263\n",
            "Evaluation: [1900/2507]  eta: 0:02:59    time: 0.2961  data: 0.0000  max mem: 6263\n",
            "Evaluation: [1950/2507]  eta: 0:02:44    time: 0.2962  data: 0.0000  max mem: 6263\n",
            "Evaluation: [2000/2507]  eta: 0:02:30    time: 0.2961  data: 0.0000  max mem: 6263\n",
            "Evaluation: [2050/2507]  eta: 0:02:15    time: 0.2962  data: 0.0000  max mem: 6263\n",
            "Evaluation: [2100/2507]  eta: 0:02:00    time: 0.2961  data: 0.0000  max mem: 6263\n",
            "Evaluation: [2150/2507]  eta: 0:01:45    time: 0.2963  data: 0.0000  max mem: 6263\n",
            "Evaluation: [2200/2507]  eta: 0:01:30    time: 0.2963  data: 0.0000  max mem: 6263\n",
            "Evaluation: [2250/2507]  eta: 0:01:16    time: 0.2963  data: 0.0000  max mem: 6263\n",
            "Evaluation: [2300/2507]  eta: 0:01:01    time: 0.2961  data: 0.0000  max mem: 6263\n",
            "Evaluation: [2350/2507]  eta: 0:00:46    time: 0.2961  data: 0.0000  max mem: 6263\n",
            "Evaluation: [2400/2507]  eta: 0:00:31    time: 0.2964  data: 0.0000  max mem: 6263\n",
            "Evaluation: [2450/2507]  eta: 0:00:16    time: 0.2963  data: 0.0000  max mem: 6263\n",
            "Evaluation: [2500/2507]  eta: 0:00:02    time: 0.2965  data: 0.0000  max mem: 6263\n",
            "Evaluation: [2506/2507]  eta: 0:00:00    time: 0.2965  data: 0.0000  max mem: 6263\n",
            "Evaluation: Total time: 0:12:22 (0.2961 s / it)\n",
            "Evaluation time 0:15:06\n",
            "{'txt_r1': 95.60878243512974, 'txt_r5': 99.8003992015968, 'txt_r10': 100.0, 'txt_r_mean': 98.46972721224218, 'img_r1': 85.95931392102113, 'img_r5': 98.48424411647387, 'img_r10': 99.2820103709613, 'img_r_mean': 94.57518946948544, 'r_mean': 96.5224583408638}\n",
            "{'val_txt_r1': 95.60878243512974, 'val_txt_r5': 99.8003992015968, 'val_txt_r10': 100.0, 'val_txt_r_mean': 98.46972721224218, 'val_img_r1': 85.95931392102113, 'val_img_r5': 98.48424411647387, 'val_img_r10': 99.2820103709613, 'val_img_r_mean': 94.57518946948544, 'val_r_mean': 96.5224583408638}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "I9pEHUK651kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fJh-lCo2tvSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "j0hRktv458GE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}